{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import attention\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup \n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lkw06\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "# Init the Wordnet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98401, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_summary = pd.read_csv(\"news_summary_more.csv\",encoding='ISO-8859-1')\n",
    "news_summary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story: Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\n",
      "Summaries: Delhi techie wins free food from Swiggy for one year on CRED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Full Stories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for one year on CRED</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-match winning streak</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's capt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customers save tax</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to Ã¢ÂÂ¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claims are not true: Sonam</td>\n",
       "      <td>Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               Summary  \\\n",
       "0    upGrad learner switches to career in ML & Al with 90% salary hike   \n",
       "1         Delhi techie wins free food from Swiggy for one year on CRED   \n",
       "2     New Zealand end Rohit Sharma-led India's 12-match winning streak   \n",
       "3             Aegon life iTerm insurance plan helps customers save tax   \n",
       "4  Have known Hirani for yrs, what if MeToo claims are not true: Sonam   \n",
       "\n",
       "                                                                                                                                                                                              Full Stories  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program ...  \n",
       "1  Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coi...  \n",
       "2  New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's capt...  \n",
       "3  With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to Ã¢ÂÂ¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, c...  \n",
       "4  Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"I...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Story: ' + str(news_summary['Full Stories'][1]))\n",
    "print('Summaries: ' + str(news_summary['Summary'][1]))\n",
    "news_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98401, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_summary.dropna(axis=0,inplace=True)\n",
    "news_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98360, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_summary.drop_duplicates(subset=['Full Stories'],inplace=True)  #dropping duplicates\n",
    "news_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCIES = {\n",
    "    \"$\": \"USD\", \"zł\": \"PLN\", \"£\": \"GBP\", \"¥\": \"JPY\", \"฿\": \"THB\", \"₡\": \"CRC\", \"₦\": \"NGN\",\"₩\": \"KRW\",\n",
    "    \"₪\": \"ILS\", \"₫\": \"VND\", \"€\": \"EUR\", \"₱\": \"PHP\", \"₲\": \"PYG\", \"₴\": \"UAH\", \"₹\": \"INR\"}\n",
    "\n",
    "CURRENCY_REGEX = re.compile(\n",
    "    \"({})+\".format(\"|\".join(re.escape(c) for c in CURRENCIES.keys())))\n",
    "\n",
    "EMAIL_REGEX = re.compile(\n",
    "    r\"(?:^|(?<=[^\\w@.)]))([\\w+-](\\.(?!\\.))?)*?[\\w+-]@(?:\\w-?)*?\\w+(\\.([a-z]{2,})){1,3}(?:$|(?=\\b))\",\n",
    "    flags=re.IGNORECASE | re.UNICODE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#English Contraction\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True):\n",
    "#     text = text.replace('(CNN) -- ', '')\n",
    "    text = text.lower()\n",
    "#     text = BeautifulSoup(text, \"lxml\").text\n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    #Remove website url\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    #Remove Email\n",
    "    text = EMAIL_REGEX.sub('',text)\n",
    "    #Remove currency symbol\n",
    "    text = CURRENCY_REGEX.sub('',text)\n",
    "    #Convert short forms to full text\n",
    "    text = ' '.join([contractions[t] if t in contractions else t for t in text.split(\" \")])    \n",
    "    #Remove Special Characters\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', '', text)\n",
    "    #Remove number from string\n",
    "    text = re.sub(r'[0-9]', \"\", text) \n",
    "    #Remove 's and backspace\n",
    "    text = re.sub(r\"'s\\b\",\"\", text)\n",
    "    #Remove ampersand\n",
    "    text = re.sub(r'&amp;', '', text)\n",
    "    #Remove newline\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(\"(\\s+)\", \" \", str(text)).lower()\n",
    "    # Remove the single character hanging between any two spaces\n",
    "    text = re.sub(\"(\\s+.\\s+)\", \" \", str(text)).lower()\n",
    "    \n",
    "    # Tokenize: Split the sentence into words\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Lemmatize list of words and join\n",
    "    text = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "    \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Text are complete.\n",
      "Summary are complete.\n"
     ]
    }
   ],
   "source": [
    "cleaned_full_text = []\n",
    "cleaned_summary = []\n",
    "for fullText in news_summary['Full Stories']:\n",
    "    cleaned_full_text.append(clean_text(fullText, remove_stopwords=True))\n",
    "print(\"Full Text are complete.\")\n",
    "\n",
    "for summary in news_summary['Summary']:    \n",
    "    cleaned_summary.append(clean_text(summary, remove_stopwords=True))\n",
    "print(\"Summary are complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(count_dict, text):\n",
    "    '''Count the number of occurrences of each word in a set of text'''\n",
    "    for sentence in text:\n",
    "        for word in sentence.split():\n",
    "            if word not in count_dict:\n",
    "                count_dict[word] = 1\n",
    "            else:\n",
    "                count_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of times each word was used and the size of the vocabulary\n",
    "word_counts = {}\n",
    "\n",
    "count_words(word_counts, cleaned_summary)\n",
    "count_words(word_counts, cleaned_full_text)\n",
    "            \n",
    "print(\"Size of Vocabulary for both text and summary:\", len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(r'C:\\Users\\lkw06\\Desktop\\numberbatch-en.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "print('Word embeddings:', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of words that are missing from the word embeddings, and are used more than our threshold.\n",
    "missing_words = 0\n",
    "threshold = 20\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    if count > threshold:\n",
    "        if word not in embeddings_index:\n",
    "            missing_words += 1\n",
    "            \n",
    "missing_ratio = round(missing_words/len(word_counts),4)*100\n",
    "            \n",
    "print(\"Number of words missing from Word Embeddings:\", missing_words)\n",
    "print(\"Percent of words that are missing from vocabulary: {}%\".format(missing_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the vocab that we will use to words that appear ≥ threshold or are in GloVe\n",
    "\n",
    "#dictionary to convert words to integers\n",
    "vocab_to_int = {} \n",
    "\n",
    "value = 0\n",
    "for word, count in word_counts.items():\n",
    "    if count >= threshold or word in embeddings_index:\n",
    "        vocab_to_int[word] = value\n",
    "        value += 1\n",
    "# Special tokens that will be added to our vocab\n",
    "codes = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]   \n",
    "\n",
    "# Add codes to vocab\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = len(vocab_to_int)\n",
    "\n",
    "# Dictionary to convert integers to words\n",
    "int_to_vocab = {}\n",
    "for word, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = word\n",
    "\n",
    "usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
    "\n",
    "print(\"Total number of unique words:\", len(word_counts))\n",
    "print(\"Number of words we will use:\", len(vocab_to_int))\n",
    "print(\"Percent of words we will use: {}%\".format(usage_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "nb_words = len(vocab_to_int)\n",
    "word_embedding_matrix = np.zeros((nb_words, embedding_dim), \n",
    "                                 dtype=np.float32)\n",
    "for word, i in vocab_to_int.items():\n",
    "    if word in embeddings_index:\n",
    "        word_embedding_matrix[i] = embeddings_index[word]\n",
    "    else:\n",
    "        # If word not in CN, create a random embedding for it\n",
    "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "        embeddings_index[word] = new_embedding\n",
    "        word_embedding_matrix[i] = new_embedding\n",
    "print(len(word_embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ints(text, word_count, unk_count, eos=False):\n",
    "    '''Convert words in text to an integer.\n",
    "       If word is not in vocab_to_int, use UNK's integer.\n",
    "       Total the number of words and UNKs.\n",
    "       Add EOS token to the end of texts'''\n",
    "    ints = []\n",
    "    for sentence in text:\n",
    "        sentence_ints = []\n",
    "        for word in sentence.split():\n",
    "            word_count += 1\n",
    "            if word in vocab_to_int:\n",
    "                sentence_ints.append(vocab_to_int[word])\n",
    "            else:\n",
    "                #UNK Means the the word didn't exist in the word embeddings\n",
    "                sentence_ints.append(vocab_to_int[\"<UNK>\"])\n",
    "                unk_count += 1\n",
    "        if eos:\n",
    "            sentence_ints.append(vocab_to_int[\"<EOS>\"])\n",
    "        ints.append(sentence_ints)\n",
    "    return ints, word_count, unk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply convert_to_ints to clean_summaries and clean_texts\n",
    "word_count = 0\n",
    "unk_count = 0\n",
    "\n",
    "int_summaries, word_count, unk_count = convert_to_ints(cleaned_summary, word_count, unk_count)\n",
    "int_texts, word_count, unk_count = convert_to_ints(cleaned_full_text, word_count, unk_count, eos=True)\n",
    "\n",
    "unk_percent = round(unk_count/word_count,4)*100\n",
    "\n",
    "print(\"Total number of words in Story and Summary:\", word_count)\n",
    "print(\"Total number of UNKs in Story and Summary:\", unk_count)\n",
    "print(\"Percent of words that are UNK: {}%\".format(unk_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lengths(text):\n",
    "    '''Create a data frame of the sentence lengths from a text'''\n",
    "    lengths = []\n",
    "    for sentence in text:\n",
    "        lengths.append(len(sentence))\n",
    "    return pd.DataFrame(lengths, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_summaries = create_lengths(int_summaries)\n",
    "lengths_texts = create_lengths(int_texts)\n",
    "\n",
    "print(\"Summaries:\")\n",
    "print(lengths_summaries.describe())\n",
    "print()\n",
    "print(\"Texts:\")\n",
    "print(lengths_texts.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unk_counter(sentence):\n",
    "    '''Counts the number of time UNK appears in a sentence.'''\n",
    "    unk_count = 0\n",
    "    for word in sentence:\n",
    "        if word == vocab_to_int[\"<UNK>\"]:\n",
    "            unk_count += 1\n",
    "    return unk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_summary['cleaned_text']=cleaned_full_text\n",
    "news_summary['cleaned_summary']=cleaned_summary\n",
    "news_summary['cleaned_text'] = news_summary['cleaned_text'].str.findall('\\w{2,}').str.join(' ')\n",
    "news_summary['cleaned_summary'] = news_summary['cleaned_summary'].str.findall('\\w{2,}').str.join(' ')\n",
    "news_summary['cleaned_summary'] = news_summary['cleaned_summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story: kunal shah credit card bill payment platform cred gave user chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coin user get one cred coin per rupee bill paid used avail reward brand like ixigo bookmyshow ubereats cultfit\n",
      "Summaries: sostok delhi techie win free food swiggy one year cred eostok\n"
     ]
    }
   ],
   "source": [
    "print('Story: ' + str(news_summary['cleaned_text'][1]))\n",
    "print('Summaries: ' + str(news_summary['cleaned_summary'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #pip install matplotlib\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "for i in cleaned_full_text:\n",
    "    text_word_count.append(len(i.split()))\n",
    "for i in cleaned_summary:\n",
    "    summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'Full Text': text_word_count, 'Summary': summary_word_count})\n",
    "length_df.hist(bins=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9997356649044327\n",
      "0.9961163074420496\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in cleaned_full_text:\n",
    "    if(len(i.split()) <= 50):\n",
    "        count += 1\n",
    "print(count/len(cleaned_full_text))\n",
    "\n",
    "count = 0\n",
    "for i in cleaned_summary:\n",
    "    if(len(i.split())<=10):\n",
    "        count += 1\n",
    "print(count/len(cleaned_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saurav kant alumnus upgrad iiitb pg program machine learning artificial intelligence wa sr system engineer infosys almost year work experience program upgrad degree career support helped transitio...</td>\n",
       "      <td>sostok upgrad learner switch career ml al salary hike eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speaking sexual harassment allegation rajkumar hirani sonam kapoor said ve known hirani many yearswhat true metoo movement get derailed metoo movement always believe woman case need reserve judgme...</td>\n",
       "      <td>sostok known hirani yr metoo claim true sonam eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>india recorded lowest odi total new zealand getting run fourth odi hamilton thursday seven india batsman dismissed singledigit score number ten batsman yuzvendra chahal topscored india previous lo...</td>\n",
       "      <td>sostok india get lowest odi total new zealand eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>week excbi director alok verma told department personnel training consider retired home ministry asked join work last day fixed tenure director thursday ministry directed immediately join dg fire ...</td>\n",
       "      <td>sostok govt directs alok verma join work day retirement eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>congress candidate shafia zubair ramgarh assembly seat rajasthan defeating bjp sukhwant singh margin vote bypoll victory congress ha taken total seat member assembly election ramgarh seat wa delay...</td>\n",
       "      <td>sostok cong win ramgarh bypoll rajasthan take total seat eostok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                 full_text  \\\n",
       "0  saurav kant alumnus upgrad iiitb pg program machine learning artificial intelligence wa sr system engineer infosys almost year work experience program upgrad degree career support helped transitio...   \n",
       "1  speaking sexual harassment allegation rajkumar hirani sonam kapoor said ve known hirani many yearswhat true metoo movement get derailed metoo movement always believe woman case need reserve judgme...   \n",
       "2  india recorded lowest odi total new zealand getting run fourth odi hamilton thursday seven india batsman dismissed singledigit score number ten batsman yuzvendra chahal topscored india previous lo...   \n",
       "3  week excbi director alok verma told department personnel training consider retired home ministry asked join work last day fixed tenure director thursday ministry directed immediately join dg fire ...   \n",
       "4  congress candidate shafia zubair ramgarh assembly seat rajasthan defeating bjp sukhwant singh margin vote bypoll victory congress ha taken total seat member assembly election ramgarh seat wa delay...   \n",
       "\n",
       "                                                           summary  \n",
       "0     sostok upgrad learner switch career ml al salary hike eostok  \n",
       "1             sostok known hirani yr metoo claim true sonam eostok  \n",
       "2             sostok india get lowest odi total new zealand eostok  \n",
       "3   sostok govt directs alok verma join work day retirement eostok  \n",
       "4  sostok cong win ramgarh bypoll rajasthan take total seat eostok  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_text_len = 50\n",
    "max_summary_length = 10\n",
    "\n",
    "cleaned_full_text = np.array(news_summary['cleaned_text'])\n",
    "cleaned_summary = np.array(news_summary['cleaned_summary'])\n",
    "\n",
    "short_full_text = []\n",
    "short_summary = []\n",
    "\n",
    "for i in range(len(cleaned_full_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_length and len(cleaned_full_text[i].split())<=max_text_len):\n",
    "        short_full_text.append(cleaned_full_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "\n",
    "df=pd.DataFrame({'full_text':short_full_text,'summary':short_summary})\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['full_text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)\n",
    "# x_tr,x_val,y_tr,y_val=train_test_split(bbcNews['cleaned_text'],bbcNews['cleaned_summary'],test_size=0.1,random_state=0,shuffle=True) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Full Text Train Set: 80390\n",
      "Length of Full Text Validation Set: 8932\n",
      "Length of Summary Train Set: 80390\n",
      "Length of Summary Validation Set: 8932\n"
     ]
    }
   ],
   "source": [
    "print('Length of Full Text Train Set: ' + str(len(x_tr)))\n",
    "print('Length of Full Text Validation Set: ' + str(len(x_val)))\n",
    "print('Length of Summary Train Set: ' + str(len(y_tr)))\n",
    "print('Length of Summary Validation Set: ' + str(len(y_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 66.13119300554668\n",
      "Total Coverage of rare words: 2.761825620537654\n",
      "Size of vocabulary in X = 28822\n"
     ]
    }
   ],
   "source": [
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))  \n",
    "\n",
    "thresh=4\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1\n",
    "\n",
    "print(\"Size of vocabulary in X = {}\".format(x_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 61.010022380072\n",
      "Total Coverage of rare words: 3.850958062437932\n",
      "Size of vocabulary in Y = 12022\n"
     ]
    }
   ],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "thresh=4\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_length, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_length, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1\n",
    "\n",
    "y_tokenizer.word_counts['sostok'],len(y_tr)\n",
    "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)\n",
    "\n",
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Full Text Train Set: 80390\n",
      "Length of Full Text Validation Set: 8932\n",
      "Length of Summary Train Set: 80390\n",
      "Length of Summary Validation Set: 8932\n"
     ]
    }
   ],
   "source": [
    "print('Length of Full Text Train Set: ' + str(len(x_tr)))\n",
    "print('Length of Full Text Validation Set: ' + str(len(x_val)))\n",
    "print('Length of Summary Train Set: ' + str(len(y_tr)))\n",
    "print('Length of Summary Validation Set: ' + str(len(y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters for Seq2Seq LSTM Model\n",
    "1. 1 layer of LSTM model for encoder\n",
    "2. Latent_dim with hidden size with a power of 2 (1,2,4,8....) \n",
    "3. Only Drop out to encoder with 0.2 or 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary from the w2v model = 28822\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      3689216     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1538816     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 12022)  3089654     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,156,790\n",
      "Trainable params: 10,156,790\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 256\n",
    "embedding_dim = 128\n",
    "print(\"Size of vocabulary from the w2v model = {}\".format(x_voc))\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.2,recurrent_dropout=0.2)\n",
    "encoder_output1, state_h, state_c = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.2,recurrent_dropout=0.2)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.2,recurrent_dropout=0.2)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80390 samples, validate on 8932 samples\n",
      "Epoch 1/50\n",
      "80390/80390 [==============================] - 316s 4ms/sample - loss: 6.0807 - val_loss: 5.7907\n",
      "Epoch 2/50\n",
      "80390/80390 [==============================] - 309s 4ms/sample - loss: 5.6370 - val_loss: 5.5149\n",
      "Epoch 3/50\n",
      "80390/80390 [==============================] - 311s 4ms/sample - loss: 5.3098 - val_loss: 5.1808\n",
      "Epoch 4/50\n",
      "80390/80390 [==============================] - 325s 4ms/sample - loss: 5.0523 - val_loss: 5.0165\n",
      "Epoch 5/50\n",
      "80390/80390 [==============================] - 320s 4ms/sample - loss: 4.8730 - val_loss: 4.8696\n",
      "Epoch 6/50\n",
      "80390/80390 [==============================] - 308s 4ms/sample - loss: 4.7229 - val_loss: 4.7594\n",
      "Epoch 7/50\n",
      "80390/80390 [==============================] - 299s 4ms/sample - loss: 4.5846 - val_loss: 4.6630\n",
      "Epoch 8/50\n",
      "80390/80390 [==============================] - 327s 4ms/sample - loss: 4.4622 - val_loss: 4.5791\n",
      "Epoch 9/50\n",
      "80390/80390 [==============================] - 306s 4ms/sample - loss: 4.3566 - val_loss: 4.5332\n",
      "Epoch 10/50\n",
      "80390/80390 [==============================] - 301s 4ms/sample - loss: 4.2576 - val_loss: 4.4647\n",
      "Epoch 11/50\n",
      "80390/80390 [==============================] - 324s 4ms/sample - loss: 4.1633 - val_loss: 4.4268\n",
      "Epoch 12/50\n",
      "80390/80390 [==============================] - 326s 4ms/sample - loss: 4.0839 - val_loss: 4.3784\n",
      "Epoch 13/50\n",
      "80390/80390 [==============================] - 627s 8ms/sample - loss: 4.0096 - val_loss: 4.3505\n",
      "Epoch 14/50\n",
      "80390/80390 [==============================] - 1025s 13ms/sample - loss: 3.9403 - val_loss: 4.3279\n",
      "Epoch 15/50\n",
      "80390/80390 [==============================] - 1024s 13ms/sample - loss: 3.8695 - val_loss: 4.2938\n",
      "Epoch 16/50\n",
      "80390/80390 [==============================] - 953s 12ms/sample - loss: 3.8005 - val_loss: 4.2711\n",
      "Epoch 17/50\n",
      "80390/80390 [==============================] - 956s 12ms/sample - loss: 3.7400 - val_loss: 4.2615\n",
      "Epoch 18/50\n",
      "80390/80390 [==============================] - 962s 12ms/sample - loss: 3.6851 - val_loss: 4.2495\n",
      "Epoch 19/50\n",
      "80390/80390 [==============================] - 961s 12ms/sample - loss: 3.6345 - val_loss: 4.2443\n",
      "Epoch 20/50\n",
      "80390/80390 [==============================] - 1144s 14ms/sample - loss: 3.5854 - val_loss: 4.2331\n",
      "Epoch 21/50\n",
      "80390/80390 [==============================] - 1109s 14ms/sample - loss: 3.5281 - val_loss: 4.2216\n",
      "Epoch 22/50\n",
      "80390/80390 [==============================] - 981s 12ms/sample - loss: 3.4744 - val_loss: 4.2186\n",
      "Epoch 23/50\n",
      "80390/80390 [==============================] - 962s 12ms/sample - loss: 3.4232 - val_loss: 4.2103\n",
      "Epoch 24/50\n",
      "80390/80390 [==============================] - 984s 12ms/sample - loss: 3.3738 - val_loss: 4.2061\n",
      "Epoch 25/50\n",
      "80390/80390 [==============================] - 1079s 13ms/sample - loss: 3.3291 - val_loss: 4.2129\n",
      "Epoch 26/50\n",
      "80390/80390 [==============================] - 1181s 15ms/sample - loss: 3.2880 - val_loss: 4.2248\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es], batch_size = 128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index = y_tokenizer.index_word\n",
    "reverse_source_word_index = x_tokenizer.index_word\n",
    "target_word_index = y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Models\n",
    "\n",
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,\n",
    "                      state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
    "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
    "                      decoder_state_input_h, decoder_state_input_c],\n",
    "                      [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "\n",
    "    # Encode the input as state vectors.\n",
    "    (e_out, e_h, e_c) = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        (output_tokens, h, c) = decoder_model.predict([target_seq]\n",
    "                + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "\n",
    "        if sampled_token != 'eostok':\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find the stop word.\n",
    "        if sampled_token == 'eostok' or len(decoded_sentence.split()) \\\n",
    "            >= max_summary_length - 1:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1)\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        (e_h, e_c) = (h, c)\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert sequence to summary\n",
    "def seq2summary(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0 and i != target_word_index['sostok'] and i != target_word_index['eostok']:\n",
    "            newString = newString + reverse_target_word_index[i] + ' '\n",
    "\n",
    "    return newString\n",
    "\n",
    "\n",
    "# To convert sequence to text\n",
    "def seq2text(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            newString = newString + reverse_source_word_index[i] + ' '\n",
    "\n",
    "    return newString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: hearing petition seeking deletion scene netflix series sacred game allegedly defamed late pm rajiv gandhi delhi high court monday observed actor held liable dialogue petition ha alleged series used derogatory language gandhi falsely depicted historical incident like bofors scam shah bano case \n",
      "Original summary: actor liable dialogue hc sacred game row \n",
      "Predicted summary:  rajiv gandhi used national anthem delhi\n",
      "\n",
      "\n",
      "Review: congress vice president rahul gandhi said saturday recent attack convoy gujarat wa carried people bjp gandhi said prime minister narendra modi way politics added done people would condemn \n",
      "Original summary: bjp people attacked convoy gujarat rahul gandhi \n",
      "Predicted summary:  rahul gandhi call pm modi gujarat cm\n",
      "\n",
      "\n",
      "Review: maker raabta rejected claim film copy telugu film magadheera added extremely disrespectful people belittle someone hard work allege plagiarism basis trailer maker magadheera accused raabta producer copying story approached court seeking injunction film release \n",
      "Original summary: raabta copy telugu film producer \n",
      "Predicted summary:  producer slam producer weinstein scene\n",
      "\n",
      "\n",
      "Review: first man walk moon neil armstrong aged wa paid trim grass cemetery ohio wa born august armstrong held several odd job childhood pay flying lesson notably small town ha museum named astronaut \n",
      "Original summary: neil armstrong mowed graveyard grass \n",
      "Predicted summary:  first person wa moon return wa\n",
      "\n",
      "\n",
      "Review: filmmaker anurag kashyap ha said woman controlling men mind college friend would tell ladki agar mana bhi toh haath hai added kashyap said across board across ha taught work level \n",
      "Original summary: friend said hold girl hand even refuse kashyap \n",
      "Predicted summary:  men get married woman say anurag kashyap\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print ('Review:', seq2text(x_tr[i]))\n",
    "    print ('Original summary:', seq2summary(y_tr[i]))\n",
    "    print ('Predicted summary:', decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: hearing petition seeking deletion scene netflix series sacred game allegedly defamed late pm rajiv gandhi delhi high court monday observed actor held liable dialogue petition ha alleged series used derogatory language gandhi falsely depicted historical incident like bofors scam shah bano case \n",
      "Original summary: actor liable dialogue hc sacred game row \n",
      "Predicted summary:  rajiv gandhi used national anthem delhi\n",
      "\n",
      "\n",
      "0\n",
      "Review: congress vice president rahul gandhi said saturday recent attack convoy gujarat wa carried people bjp gandhi said prime minister narendra modi way politics added done people would condemn \n",
      "Original summary: bjp people attacked convoy gujarat rahul gandhi \n",
      "Predicted summary:  rahul gandhi call pm modi gujarat cm\n",
      "\n",
      "\n",
      "1\n",
      "Review: maker raabta rejected claim film copy telugu film magadheera added extremely disrespectful people belittle someone hard work allege plagiarism basis trailer maker magadheera accused raabta producer copying story approached court seeking injunction film release \n",
      "Original summary: raabta copy telugu film producer \n",
      "Predicted summary:  producer slam producer weinstein scene\n",
      "\n",
      "\n",
      "2\n",
      "Review: first man walk moon neil armstrong aged wa paid trim grass cemetery ohio wa born august armstrong held several odd job childhood pay flying lesson notably small town ha museum named astronaut \n",
      "Original summary: neil armstrong mowed graveyard grass \n",
      "Predicted summary:  first person wa moon return wa\n",
      "\n",
      "\n",
      "3\n",
      "Review: filmmaker anurag kashyap ha said woman controlling men mind college friend would tell ladki agar mana bhi toh haath hai added kashyap said across board across ha taught work level \n",
      "Original summary: friend said hold girl hand even refuse kashyap \n",
      "Predicted summary:  men get married woman say anurag kashyap\n",
      "\n",
      "\n",
      "4\n",
      "Review: cctv footage preschool united state new orleans show burglar entering unlocked window food beverage staff room napping makeshift bed stuffed toy suspect wa seen carrying two bag stolen property fleeing unknown direction said police department \n",
      "Original summary: burglar recorded napping stuffed toy \n",
      "Predicted summary:  video show pizza restaurant\n",
      "\n",
      "\n",
      "5\n",
      "Review: activist hussain started campaign seeking justice eightyearold kathua rape victim ha accused rape jnu student complainant said hussain took flat kept repeating would marry raped following accusation lawyer indira jaising said represent hussain kathua case anymore \n",
      "Original summary: activist seeking justice kathua rape victim accused rape \n",
      "Predicted summary:  activist accused rape accused kathua rape case\n",
      "\n",
      "\n",
      "6\n",
      "Review: scientist discovered new specie reef fish depth foot near remote brazilian island chain named life rocky twilight zone reef sunlight scarce it wa enchanting made ignore everything around itã scientist said noticing foot shark \n",
      "Original summary: diver discover new fish notice foot shark \n",
      "Predicted summary:  new new specie specie found near punjab\n",
      "\n",
      "\n",
      "7\n",
      "Review: gupta secretary bjp mumbai unit tagged maharashtra chief minister devendra fadnavis minister vinod tawde tweeted acre land leased government film city subhash ghai film school gupta added action must taken view sexual harassment charge ghai police complaint ha filed \n",
      "Original summary: land ghai film school bjp leader \n",
      "Predicted summary:  maha govt denies role role bjp minister\n",
      "\n",
      "\n",
      "8\n",
      "Review: dalit bjp mp ha written prime minister narendra modi uttar pradesh chief minister yogi adityanath claiming adityanath scolded thrown mp claimed wa facing discrimination administration constituency complaint heard pm modi reportedly assured action taken \n",
      "Original summary: dalit bjp mp complains pm modi cm adityanath \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-099f7ee8eeb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Review:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq2text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Original summary:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq2summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted summary:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-56ee3d3988c6>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Encode the input as state vectors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0me_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_c\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Generate empty target sequence of length 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ev_2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ev_2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ev_2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m               total_epochs=1)\n\u001b[0m\u001b[0;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ev_2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ev_2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ev_2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ev_2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ev_2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ev_2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ev_2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ev_2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ev_2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from rouge import Rouge\n",
    "rouge=Rouge()\n",
    "rouge1_prec = 0\n",
    "rouge1_recall = 0\n",
    "rouge1_f = 0\n",
    "\n",
    "rouge2_prec = 0\n",
    "rouge2_recall = 0\n",
    "rouge2_f = 0\n",
    "for i in range(0,len(x_tr)):\n",
    "    print ('Review:', seq2text(x_tr[i]))\n",
    "    print ('Original summary:', seq2summary(y_tr[i]))\n",
    "    print ('Predicted summary:', decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print ('\\n')\n",
    "    print(i)\n",
    "    rouge_scores = rouge.get_scores(seq2summary(y_tr[i]),decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    rouge1_prec +=rouge_scores[0].get('rouge-1').get('p')\n",
    "    rouge1_recall +=rouge_scores[0].get('rouge-1').get('r')\n",
    "    rouge1_f +=rouge_scores[0].get('rouge-1').get('f')\n",
    "    \n",
    "    rouge2_prec +=rouge_scores[0].get('rouge-2').get('p')\n",
    "    rouge2_recall +=rouge_scores[0].get('rouge-2').get('r')\n",
    "    rouge2_f +=rouge_scores[0].get('rouge-2').get('f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
